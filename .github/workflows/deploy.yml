name: Deploy to EC2

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Create deployment package
      run: |
        # Create temporary directory
        mkdir -p deployment
        
        # Copy necessary files
        cp -r app deployment/
        cp -r scripts deployment/ 2>/dev/null || mkdir -p deployment/scripts
        cp requirements.txt deployment/
        cp Dockerfile deployment/
        cp docker-compose.yml deployment/  # IMPORTANT: Copy docker-compose.yml
        cp docker-compose.prod.yml deployment/ 2>/dev/null || true
        cp .dockerignore deployment/
        
        # Create .env file with production secrets
        cat > deployment/.env << EOF
        APP_NAME="SkinSense AI"
        APP_VERSION="1.0.0"
        DEBUG=false
        MONGODB_URL=${{ secrets.MONGODB_URL }}
        DATABASE_NAME=skinpal
        REDIS_URL=redis://redis:6379
        SECRET_KEY=${{ secrets.SECRET_KEY }}
        ALGORITHM=HS256
        ACCESS_TOKEN_EXPIRE_MINUTES=60
        REFRESH_TOKEN_EXPIRE_DAYS=30
        ORBO_AI_API_KEY=${{ secrets.ORBO_AI_API_KEY }}
        ORBO_API_KEY=${{ secrets.ORBO_AI_API_KEY }}
        ORBO_CLIENT_ID=${{ secrets.ORBO_CLIENT_ID }}
        ORBO_CLIENTID=${{ secrets.ORBO_CLIENT_ID }}
        OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
        PERPLEXITY_API_KEY=${{ secrets.PERPLEXITY_API_KEY }}
        AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION=${{ secrets.AWS_REGION }}
        S3_BUCKET_NAME=${{ secrets.S3_BUCKET_NAME }}
        CLOUDFRONT_DOMAIN=${{ secrets.CLOUDFRONT_DOMAIN }}
        ZEPTOMAIL_SEND_TOKEN=${{ secrets.ZEPTOMAIL_SEND_TOKEN }}
        ZEPTOMAIL_HOST=api.zeptomail.com
        ZEPTOMAIL_DOMAIN=skinsense.app
        FIREBASE_PROJECT_ID=${{ secrets.FIREBASE_PROJECT_ID }}
        FIREBASE_SERVICE_ACCOUNT_PATH=/app/credentials/firebase-service-account.json
        PROMETHEUS_URL=http://prometheus:9090
        GRAFANA_URL=http://grafana:3001
        EOF
        
        # Create Firebase credentials if provided
        if [ ! -z "${{ secrets.FIREBASE_SERVICE_ACCOUNT }}" ]; then
          mkdir -p deployment/credentials
          echo "${{ secrets.FIREBASE_SERVICE_ACCOUNT }}" | base64 -d > deployment/credentials/firebase-service-account.json
        fi
        
        # Create tarball
        tar -czf deployment.tar.gz -C deployment .
    
    - name: Setup SSH key
      run: |
        mkdir -p ~/.ssh
        
        # Decode EC2 key with error handling
        echo "${{ secrets.EC2_KEY }}" | base64 -d > ~/.ssh/ec2_key.pem 2>/dev/null || {
          echo "‚ùå Failed to decode EC2_KEY. Make sure it's properly base64 encoded."
          echo "To encode your key: base64 -i your-key.pem | tr -d '\n'"
          exit 1
        }
        
        chmod 600 ~/.ssh/ec2_key.pem
        ssh-keyscan -H ${{ secrets.EC2_HOST }} >> ~/.ssh/known_hosts
    
    - name: Copy deployment package to EC2
      run: |
        scp -i ~/.ssh/ec2_key.pem deployment.tar.gz ${{ secrets.EC2_USER }}@${{ secrets.EC2_HOST }}:~/
    
    - name: Deploy on EC2 with Docker Compose
      run: |
        ssh -i ~/.ssh/ec2_key.pem ${{ secrets.EC2_USER }}@${{ secrets.EC2_HOST }} << 'ENDSSH'
        echo "üöÄ Starting deployment..."
        
        # STEP 1: Upgrade docker-compose to fix ContainerConfig bug
        echo "üì¶ Step 1: Checking and upgrading docker-compose..."
        COMPOSE_VERSION=$(docker-compose --version 2>/dev/null | grep -oE '[0-9]+\.[0-9]+\.[0-9]+' || echo "0.0.0")
        echo "Current docker-compose version: $COMPOSE_VERSION"
        
        # Install Docker Compose v2 (plugin version) which doesn't have the ContainerConfig bug
        echo "Installing Docker Compose v2 (plugin)..."
        sudo mkdir -p /usr/local/lib/docker/cli-plugins
        sudo curl -SL https://github.com/docker/compose/releases/download/v2.24.0/docker-compose-linux-x86_64 -o /usr/local/lib/docker/cli-plugins/docker-compose
        sudo chmod +x /usr/local/lib/docker/cli-plugins/docker-compose
        
        # Also update standalone docker-compose
        sudo curl -SL https://github.com/docker/compose/releases/download/v2.24.0/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose
        sudo chmod +x /usr/local/bin/docker-compose
        
        echo "Docker Compose updated to: $(docker-compose version)"
        
        # STEP 2: Clean up with proper docker-compose down
        echo "üì¶ Step 2: Cleaning up existing deployment..."
        # Use --remove-orphans to clean up any services removed from compose file
        cd ~/skinsense-backend 2>/dev/null && docker-compose down --volumes --remove-orphans 2>/dev/null || true
        # Also try with project name in case it's different
        cd ~/skinsense-backend 2>/dev/null && docker-compose -p skinsense-backend down --volumes --remove-orphans 2>/dev/null || true
        
        # STEP 3: Nuclear cleanup of corrupted containers
        echo "üì¶ Step 3: Removing corrupted containers, volumes, and networks..."
        
        # Stop and remove all containers related to skinsense
        docker ps -a --format "{{.Names}}" | grep -E "skinsense|backend" | xargs -r docker rm -f 2>/dev/null || true
        docker ps -aq | xargs -r docker rm -f 2>/dev/null || true
        
        # Remove volumes
        docker volume ls -q | grep -E "skinsense|backend" | xargs -r docker volume rm -f 2>/dev/null || true
        docker volume ls -q | xargs -r docker volume rm -f 2>/dev/null || true
        
        # Force remove the skinsense networks (multiple attempts)
        echo "Removing Docker networks..."
        docker network disconnect -f skinsense-backend_default $(docker ps -aq) 2>/dev/null || true
        docker network disconnect -f skinsense_network $(docker ps -aq) 2>/dev/null || true
        docker network rm skinsense-backend_default 2>/dev/null || true
        docker network rm skinsense_network 2>/dev/null || true
        docker network rm $(docker network ls -q --filter "name=skinsense") 2>/dev/null || true
        
        # Remove all custom networks (keep default ones)
        docker network ls --format "{{.Name}}" | grep -v "bridge\|host\|none" | xargs -r docker network rm 2>/dev/null || true
        docker network prune -f 2>/dev/null || true
        
        # STEP 4: Clean Docker system
        echo "üì¶ Step 4: Cleaning Docker system..."
        docker system prune -af --volumes 2>/dev/null || true
        
        # If still having issues, restart Docker daemon
        if docker ps 2>&1 | grep -q "ContainerConfig"; then
          echo "‚ö†Ô∏è ContainerConfig error detected, restarting Docker..."
          sudo systemctl restart docker
          sleep 5
        fi
        
        # CRITICAL: Clean networks BEFORE creating new deployment directory
        echo "üî® Pre-deployment network cleanup..."
        
        # Stop any running containers in the old deployment first
        if [ -d ~/skinsense-backend ]; then
          cd ~/skinsense-backend
          # Try to stop gracefully with docker-compose
          docker-compose down --volumes --remove-orphans 2>/dev/null || true
          cd ~
        fi
        
        # Force remove all skinsense-related networks
        echo "Removing all skinsense-related networks..."
        for network in $(docker network ls --format "{{.Name}}" | grep -E "skinsense|backend" || true); do
          echo "Found network: $network"
          # Force disconnect all containers
          for container in $(docker network inspect $network --format '{{range .Containers}}{{.Name}} {{end}}' 2>/dev/null || true); do
            docker network disconnect -f $network $container 2>/dev/null || true
          done
          # Remove the network
          docker network rm $network 2>/dev/null || true
        done
        
        # Clean up any dangling networks
        docker network prune -f 2>/dev/null || true
        
        # Backup old deployment
        if [ -d ~/skinsense-backend ]; then
          mv ~/skinsense-backend ~/skinsense-backend.backup.$(date +%Y%m%d_%H%M%S)
        fi
        
        # Create new deployment directory
        mkdir -p ~/skinsense-backend
        cd ~/skinsense-backend
        
        # Extract deployment package
        tar -xzf ~/deployment.tar.gz
        rm ~/deployment.tar.gz
        
        # Verify docker-compose.yml exists
        if [ ! -f docker-compose.yml ]; then
          echo "‚ùå docker-compose.yml not found!"
          exit 1
        fi
        
        echo "‚úÖ docker-compose.yml found"
        
        # Deploy with docker-compose
        echo "üî® Building and deploying with Docker Compose..."
        
        # FINAL AGGRESSIVE CLEANUP right before docker-compose
        echo "Final cleanup before docker-compose..."
        
        # Find and stop any container or process using port 6379 or 8000
        echo "Freeing up ports 6379 and 8000..."
        
        # Check what's using the ports
        echo "Checking port usage..."
        sudo lsof -i :6379 2>/dev/null || true
        sudo lsof -i :8000 2>/dev/null || true
        
        # Kill any system Redis that might be running
        sudo systemctl stop redis-server 2>/dev/null || true
        sudo systemctl stop redis 2>/dev/null || true
        sudo pkill -f redis-server 2>/dev/null || true
        
        # Find and stop Docker containers using these ports
        for port in 6379 8000; do
          CONTAINER_ID=$(docker ps -q --filter "publish=$port")
          if [ ! -z "$CONTAINER_ID" ]; then
            echo "Stopping container using port $port: $CONTAINER_ID"
            docker stop $CONTAINER_ID 2>/dev/null || true
            docker rm -f $CONTAINER_ID 2>/dev/null || true
          fi
        done
        
        # Remove specific named containers that might exist
        echo "Removing any existing skinsense containers..."
        docker rm -f skinsense_redis 2>/dev/null || true
        docker rm -f skinsense_api 2>/dev/null || true
        docker rm -f skinsense-backend_redis_1 2>/dev/null || true
        docker rm -f skinsense-backend_api_1 2>/dev/null || true
        
        # Stop and remove ALL containers to free up names and networks
        docker stop $(docker ps -aq) 2>/dev/null || true
        docker rm -f $(docker ps -aq) 2>/dev/null || true
        
        # Remove the specific network that's causing issues
        docker network rm skinsense-backend_app_network 2>/dev/null || true
        docker network rm skinsense-backend_default 2>/dev/null || true
        
        # Remove ALL networks that contain 'skinsense' or 'backend'
        for net in $(docker network ls -q); do
          name=$(docker network inspect $net --format '{{.Name}}' 2>/dev/null || true)
          if echo "$name" | grep -qE "skinsense|backend"; then
            echo "Force removing network: $name"
            # Disconnect any remaining containers
            docker network disconnect -f $name $(docker ps -aq) 2>/dev/null || true
            # Force remove
            docker network rm -f $net 2>/dev/null || true
          fi
        done
        
        # Prune all unused networks
        docker network prune -f 2>/dev/null || true
        
        # Show current networks for debugging
        echo "Networks after final cleanup:"
        docker network ls
        
        # Small delay to ensure cleanup is complete
        sleep 2
        
        # Build and start services with explicit project name to avoid conflicts
        echo "Building and starting services with project name..."
        PROJECT_NAME="skinsense-$(date +%s)"
        echo "Using project name: $PROJECT_NAME"
        
        # Build with explicit project name
        docker-compose -p $PROJECT_NAME build --no-cache
        
        # Start with explicit project name and force recreate
        docker-compose -p $PROJECT_NAME up -d --force-recreate --remove-orphans
        
        # Store project name for future reference
        echo $PROJECT_NAME > ~/.current_project_name
        
        # Wait for services to start
        echo "Waiting for services to start..."
        sleep 15
        
        echo "Checking container status..."
        docker-compose -p $PROJECT_NAME ps
        
        echo "Fetching logs..."
        docker-compose -p $PROJECT_NAME logs --tail=50
        
        echo "‚úÖ Docker Compose deployment completed!"
        
        # Health check
        echo "üè• Running health check..."
        sleep 5
        
        # Show current container status
        echo "Current container status:"
        docker ps -a
        
        # Try health check multiple times
        HEALTH_CHECK_ATTEMPTS=3
        HEALTH_CHECK_PASSED=false
        
        for i in $(seq 1 $HEALTH_CHECK_ATTEMPTS); do
          echo "Health check attempt $i of $HEALTH_CHECK_ATTEMPTS..."
          if curl -f http://localhost:8000/health 2>/dev/null; then
            HEALTH_CHECK_PASSED=true
            echo "‚úÖ Health check passed!"
            break
          else
            echo "Health check attempt $i failed, waiting 10 seconds..."
            sleep 10
          fi
        done
        
        if [ "$HEALTH_CHECK_PASSED" = true ]; then
          echo "üéâ Deployment successful!"
          echo "üìä Service status:"
          docker ps
        else
          echo "‚ùå Health check failed after $HEALTH_CHECK_ATTEMPTS attempts."
          echo "Container status:"
          docker ps -a
          echo ""
          echo "Detailed logs:"
          if command -v docker &> /dev/null && docker compose version &> /dev/null; then
            docker compose -p skinsense logs --tail=200
          else
            docker-compose -p skinsense logs --tail=200
          fi
          echo ""
          echo "Checking specific container logs:"
          docker logs skinsense_api --tail=100 2>&1 || echo "Could not get API container logs"
          docker logs skinsense_redis --tail=50 2>&1 || echo "Could not get Redis container logs"
          exit 1
        fi
        ENDSSH
    
    - name: Clean up
      if: always()
      run: |
        rm -f ~/.ssh/ec2_key.pem
        rm -f deployment.tar.gz
        rm -rf deployment/
    
    - name: Notify deployment status
      if: always()
      run: |
        if [ ${{ job.status }} == 'success' ]; then
          echo "üöÄ Deployment to EC2 successful!"
          echo "API URL: http://${{ secrets.EC2_HOST }}:8000"
          echo "Documentation: http://${{ secrets.EC2_HOST }}:8000/docs"
        else
          echo "‚ùå Deployment failed. Check the logs for details."
        fi